{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261fb2c1-3965-474a-987e-a64113b30d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!~/.conda/envs/lra/bin/python3\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict \n",
    "import numpy as np\n",
    "# import UnionFind\n",
    "import edlib\n",
    "import math\n",
    "\n",
    "path = \"/project/mchaisso_100/cmb-16/jingwenr/trfCall/revision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178d89a9-cc3a-438a-8a51-c7b667ccd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressions = [\"original\", \"q-0.1\", \"q-0.2\"]\n",
    "path = \"/project/mchaisso_100/cmb-16/jingwenr/trfCall/revision/special_loci/anno_combined_subject10\"\n",
    "samples = [file.rstrip('.anno.vcf') for file in os.listdir(f\"{path}/original\") if file.startswith('Sub')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac730f1e-38f7-4363-986a-2cffe3a9abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseVCF_twoHaps(input_file_path, out_file_path_h1, out_file_path_h2):\n",
    "    \n",
    "    with open(input_file_path, 'r') as fin, \\\n",
    "         open(out_file_path_h1, 'w') as fout_h1, \\\n",
    "         open(out_file_path_h2, 'w') as fout_h2: \n",
    "        \n",
    "        lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('#'):\n",
    "                fout_h1.write(line)\n",
    "                fout_h2.write(line)\n",
    "                continue \n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            fields = line.split('\\t')\n",
    "#             print(len(fields), fields)\n",
    "            infos = fields[7]\n",
    "            info_subfields = infos.split(';')\n",
    "            end, ru, svtype = info_subfields[0], info_subfields[1], info_subfields[2]\n",
    "            h1_anno, h1_len = info_subfields[3], info_subfields[4]\n",
    "            if len(info_subfields) > 6:\n",
    "                h2_anno, h2_len = info_subfields[5], info_subfields[6]\n",
    "            \n",
    "            fields[7] = ';'.join([end, ru, svtype, h1_anno, h1_len]) + \";\"\n",
    "            fout_h1.write('\\t'.join(fields) + \"\\n\")\n",
    "            \n",
    "            if len(info_subfields) > 6:\n",
    "                fields[7] = ';'.join([end, ru, svtype, h2_anno, h2_len]) + \";\"\n",
    "                fout_h2.write('\\t'.join(fields) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cdfaf6f-19db-461b-99ab-de46c7212563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for compression in compressions:\n",
    "    for sample in samples:\n",
    "        input_file_path = f\"{path}/{compression}/{sample}.anno.vcf\"\n",
    "        out_file_path_h1 = f\"{path}/{compression}/{sample}_h1.anno.vcf\"\n",
    "        out_file_path_h2 = f\"{path}/{compression}/{sample}_h2.anno.vcf\"\n",
    "        parseVCF_twoHaps(input_file_path, out_file_path_h1, out_file_path_h2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
